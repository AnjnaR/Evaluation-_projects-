{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ef779059",
   "metadata": {},
   "source": [
    "# CENSUS\n",
    "A census is the procedure of systematically calculating, acquiring and recording information about the members of a given population. This term is used mostly in connection with national population and housing censuses; other common censuses include the census of agriculture, and other censuses such as the traditional culture, business, supplies, and traffic censuses. The United Nations defines the essential features of population and housing censuses as \"individual enumeration, universality within a defined territory, simultaneity and defined periodicity\", and recommends that population censuses be taken at least every ten years. United Nations recommendations also cover census topics to be collected, official definitions, classifications and other useful information to co-ordinate international practices.\n",
    "\n",
    "###DATA DESCRIPTION\n",
    "Problem Statement:\n",
    "This data was extracted from the 1994 Census bureau database by Ronny Kohavi and Barry Becker (Data Mining and Visualization, Silicon Graphics). A set of reasonably clean records was extracted using the following conditions: ((AAGE>16) && (AGI>100) && (AFNLWGT>1) && (HRSWK>0)). The prediction task is to determine whether a person makes over $50K a year.\n",
    "\n",
    "Description of fnlwgt (final weight) :\n",
    "The weights on the Current Population Survey (CPS) files are controlled to independent estimates of the civilian non-institutional population of the US. These are prepared monthly for us by Population Division here at the Census Bureau. We use 3 sets of controls. These are:\n",
    "\n",
    "A single cell estimate of the population 16+ for each state.\n",
    "\n",
    "Controls for Hispanic Origin by age and sex.\n",
    "\n",
    "Controls by Race, age and sex.\n",
    "\n",
    "We use all three sets of controls in our weighting program and \"rake\" through them 6 times so that by the end we come back to all the controls we used. The term estimate refers to population totals derived from CPS by creating \"weighted tallies\" of any specified socio-economic characteristics of the population. People with similar demographic characteristics should have similar weights. There is one important caveat to remember about this statement. That is that since the CPS sample is actually a collection of 51 state samples, each with its own probability of selection, the statement only applies within state."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "938aac26",
   "metadata": {},
   "outputs": [],
   "source": [
    "#LOADING DATA SET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1920c14c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "path ='https://raw.githubusercontent.com/dsrscientist/dataset1/master/census_income.csv'\n",
    "df= pd.read_csv(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a02cc1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9ca783e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2cbb3cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6eb3e032",
   "metadata": {},
   "outputs": [],
   "source": [
    "Details About The Columns\n",
    " 1. Age\n",
    "\n",
    "This Column shows the Individuals Age Years\n",
    "\n",
    " 2. Work Class\n",
    "\n",
    "This Column shows the Individuals Occupoation\n",
    "\n",
    " 3. Fnlwgt\n",
    "\n",
    "This Column shows the Individuals Final Wieght\n",
    "\n",
    " 4. Education\n",
    "\n",
    "This Column shows the Individuals Education Level\n",
    "\n",
    " 5. Education_num\n",
    "\n",
    "This Column shows the Individuals Educations Num\n",
    "\n",
    " 6. Marital_Status\n",
    "\n",
    "This Column shows the Individuals Maritasl status That is whether married or not\n",
    "\n",
    " 7. Occupation\n",
    "\n",
    "This Column shows the Individuals Details of the Work Occupation\n",
    "\n",
    "8. Relationship\n",
    "\n",
    "This Column shows the Individuals Realtionship whith the Individual\n",
    "\n",
    "9. Sex \n",
    "\n",
    "This Column shows the Individuals Sex that is which gender he belongs to\n",
    "\n",
    "10. Race\n",
    "\n",
    "This Column shows the Individuals Race or Region of origin details\n",
    "\n",
    "11. Capital Gain\n",
    "\n",
    "This Column shows the Individuals Capital gain or net worth\n",
    "\n",
    "12. Capital Loss\n",
    "\n",
    "This Column shows the Individuals Capital loss\n",
    "\n",
    "13. Hours Per Week\n",
    "\n",
    "This Column shows the Individuals working hours per week\n",
    "\n",
    "14. Native_Country\n",
    "\n",
    "This Column shows the Individuals Shows the country or statte from which he belongs\n",
    "\n",
    "15. Income\n",
    "\n",
    "This Column shows the Individuals income is more or less than 50k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abdaf668",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data Exploration\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a31c8b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_cols=df.select_dtypes([object])\n",
    "\n",
    "for col in cat_cols.columns:\n",
    "    print(col)\n",
    "    print(df[col].value_counts())\n",
    "    print('*****************************************************')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01483ee0",
   "metadata": {},
   "source": [
    "OUTCOME : -\n",
    "Native.Country, Occupation,Workclass\n",
    "\n",
    "  * It has unknown values represented by ?\n",
    "\n",
    "Education\n",
    "\n",
    " * 9th, 10th, 11th, 12th comes under HighSchool Grad but it has mentioned separately\n",
    "\n",
    " * Creating Elementary object for 1st-4th, 5th-6th, 7th-8th\n",
    "Marital Status\n",
    "\n",
    " * Married-civ-spouse,Married-spouse-absent,Married-AF-spouse comes under category Married\n",
    "\n",
    " * Divorced, separated again comes under category separated.\n",
    "Workclass\n",
    "\n",
    " * Self-emp-not-inc, Self-emp-inc comes under category self employed\n",
    "\n",
    " * Local-gov,State-gov,Federal-gov comes under category goverment emloyees\n",
    "Removing the rows with no Values ( ? )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0e65d31",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(df[df['Native_country'] == ' ?'].index)\n",
    "df = df.drop(df[df['Occupation'] == ' ?'].index)\n",
    "df = df.drop(df[df['Workclass'] == ' ?'].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e80cd98",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Native_country'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c7d5eca",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Occupation'].value_counts()\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46bb0837",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Workclass'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef44b961",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Hours_per_week'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c41c57cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Hours_per_week'] = pd.cut(df['Hours_per_week'], \n",
    "                                   bins = [0, 30, 40, 100], \n",
    "                                   labels = ['Lesser Hours', 'Normal Hours', 'Extra Hours'])\n",
    "df['Hours_per_week'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92f54c94",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Capital Diff'] = df['Capital_gain'] - df['Capital_loss']\n",
    "df.drop(['Capital_gain'], axis = 1, inplace = True)\n",
    "df.drop(['Capital_loss'], axis = 1, inplace = True)\n",
    "df['Capital Diff'] = pd.cut(df['Capital Diff'], bins = [-5000, 5000, 100000], labels = ['Minor', 'Major'])\n",
    "df['Age'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dcd4de2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Age'] = pd.cut(df['Age'], bins = [0, 25, 50, 100], labels = ['Young', 'Adult', 'Old'])\n",
    "df['Age'].value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07a1453b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Education'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d6fd37a",
   "metadata": {},
   "outputs": [],
   "source": [
    "education_classes = df['Education'].unique()\n",
    "for edu_class in education_classes:\n",
    "    print(\"For {}, the Education Number is {}\"\n",
    "          .format(edu_class, df[df['Education'] == edu_class]['Education_num'].unique()))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77292465",
   "metadata": {},
   "source": [
    "From the above we discovered that Education Number and Education are just the same. So, I can drop any one column. Also, I'll combine all information from Preschool to 12th as they can be considered of one class who have no college/university level education."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dec88f39",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(['Education_num'], axis = 1, inplace = True)\n",
    "df['Education'].replace([' 7th-8th', ' 5th-6th',' 1st-4th', ' Preschool',' 11th', ' 9th', ' 10th', ' 12th'],\n",
    "                             ' School', inplace = True)\n",
    "\n",
    "df['Education'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e656e435",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Native_country'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a329082d",
   "metadata": {},
   "source": [
    "We can see that The majority of adults are from United States. Thus, we can distribute the column with values as either United States or Other."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a10b732",
   "metadata": {},
   "outputs": [],
   "source": [
    "Native_countrys = np.array(df['Native_country'].unique())\n",
    "Native_countrys = np.delete(Native_countrys, 0)\n",
    "df['Native_country'].replace(Native_countrys, 'Other', inplace = True)\n",
    "df['Native_country'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "164f00ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Race'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65f6d1e7",
   "metadata": {},
   "source": [
    "we can see that The dataset includes majority of information about White race while all other races are lesser in number. I'll combine all other race data into one class as Other."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f3b17e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Race'].unique()\n",
    "df['Race'].replace([' Black', ' Asian-Pac-Islander', ' Amer-Indian-Eskimo', ' Other'],' Other', inplace = True)\n",
    "df['Race'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a10e4e4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9101e254",
   "metadata": {},
   "source": [
    "# Checking for the Columns containing Null , Blank Or Empty Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4393b5ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78bc7487",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b7369b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "sns.heatmap(df.isnull())\n",
    "plt.title(\"Null Values\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9bda395",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Checking and Transforming the Data types of the Columns To Same DataTypes for Better Analysis\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb6f8081",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4c8e964",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8afe8abd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "le =LabelEncoder()\n",
    "\n",
    "list1=['Workclass','Education','Marital_status','Occupation','Relationship','Race','Sex','Native_country','Income']\n",
    "for val in list1:\n",
    "  df[val]=le.fit_transform(df[val].astype(str))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25d7d313",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71d0cc06",
   "metadata": {},
   "source": [
    "# Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dc51c80",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize =(12,6));\n",
    "sns.countplot(x = 'Income', data = df);\n",
    "plt.xlabel(\"Income\",fontsize = 12);\n",
    "plt.ylabel(\"Frequency\",fontsize = 12);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8bbc44f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b631be74",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90878cfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(df['Workclass'].value_counts())  \n",
    "plt.figure(figsize=(10,10))\n",
    "sns.countplot(df['Workclass'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffd6099b",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (10,6))\n",
    "plt.title(\"Comparision between Age and Income\")\n",
    "sns.barplot(x = \"Age\", y = \"Income\", data = df)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36223f69",
   "metadata": {},
   "source": [
    "We can see that the age Group between 50\n",
    "100 Years are more in numbers compared to the younger ones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34742e72",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (10,6))\n",
    "plt.title(\"Comparision between Education and Income\")\n",
    "sns.barplot(x = \"Education\", y = \"Income\", data = df)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a64a6a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (10,6))\n",
    "plt.title(\"Comparision between Marital_Status and Income\")\n",
    "sns.barplot(x = \"Marital_status\", y = \"Income\", data = df)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2e3d844",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (20,10))\n",
    "plt.title(\"Comparision between Occupation and Income\")\n",
    "sns.barplot(x = \"Occupation\", y = \"Income\", data = df)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2309fdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (10,6))\n",
    "plt.title(\"Comparision between Relationship and Income\")\n",
    "sns.barplot(x = \"Relationship\", y = \"Income\", data = df)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "931537a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (10,6))\n",
    "plt.title(\"Comparision between Race and Income\")\n",
    "sns.barplot(x = \"Race\", y = \"Income\", data = df)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7bf46d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (10,6))\n",
    "plt.title(\"Comparision between Sex and Income\")\n",
    "sns.barplot(x = \"Sex\", y = \"Income\", data = df)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05fb0cd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (10,6))\n",
    "plt.title(\"Comparision between Native_country and Income\")\n",
    "sns.barplot(x = \"Native_country\", y = \"Income\", data = df)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98167f8b",
   "metadata": {},
   "source": [
    "Our dataset has 25000 people earning <=50K i.e. 75% and remainng 25% earns more than 50K.\n",
    "We can see that the private workclass person are more in compare to all\n",
    "We can see that the age Group between 50\n",
    "100 Years are more in numbers compared to the younger ones\n",
    "we can see that the educationis evenly distributed with Doctorate as the highest among all\n",
    "We can see that the ratio of Married-Af-Spouse no's are too higher than any other\n",
    "We can see that the Occupation columnn has The Highest No of Exec Manager followed proffesor speciality..\n",
    "We can see that the in relationship wifes are the max in number\n",
    "In context of race the white mens are the most in the census income ratio than any other combined\n",
    "\n",
    "In context of the sex ratio we can see that the Male are morein number than any other\n",
    "With respect to Native Country the ratio of Usa Citizen is much more higher than the others\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a54135e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.plot.scatter(x='Income',y='Fnlwgt')\n",
    "df.plot.scatter(x='Income',y='Hours_per_week')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b8f2f1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.hist(figsize=(15,30),edgecolor='red',layout=(9,3),bins=15,legend=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63bc3009",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pairplot(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32ef05ba",
   "metadata": {},
   "source": [
    "# Corealtion between features and target ' INCOME ' ( EDA )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "396280ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88b9ea5b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1554bf2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d881423",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Coorelation with the Target Column Primary Fuel \n",
    "\n",
    "df.corr()['Income'].sort_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8677606",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "plt.figure(figsize=(15,7))\n",
    "sns.heatmap(df.corr(), annot=True, linewidths=0.5,linecolor=\"black\", fmt='.2f')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07b98ac2",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Dropping the irrelevant columns..\n",
    "\n",
    "df.drop(columns=[\"Fnlwgt\"], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaa4b0e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Descriptive Statistics\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afb9f4bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,7))\n",
    "sns.heatmap(round(df.describe()[1:].transpose(),2), annot=True, linewidths=0.5,linecolor=\"black\", fmt='f')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06f87156",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "355f6a06",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Checking Skewness\n",
    "my_column1 = df.pop('Income')\n",
    "df.insert(11,'Income', my_column1) \n",
    "\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cc8185c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.iloc[:,:-1].skew()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ed3c9ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import power_transform\n",
    "x_new=power_transform(df.iloc[:,:-1],method='yeo-johnson')\n",
    "\n",
    "df.iloc[:,:-1]=pd.DataFrame(x_new,columns=df.iloc[:,:-1].columns)\n",
    "df.iloc[:,:-1].skew()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca1bf6a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "Outliers Checking\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "df.plot(kind='box',subplots=True, layout=(3,5), figsize=[20,8])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73c61278",
   "metadata": {},
   "source": [
    "###IQR Proximity Rule\n",
    "Z - Score Technique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29ea2ca5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import zscore\n",
    "import numpy as np\n",
    "z=np.abs(zscore(df))\n",
    "z.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87120470",
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold=3\n",
    "print(np.where(z>3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e6bbf74",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(np.where(z>3)[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2009729",
   "metadata": {},
   "source": [
    "We can see that there are no outliers present\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fb3b739",
   "metadata": {},
   "outputs": [],
   "source": [
    "Feature Engineering ( VIF )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ea7ff6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "df.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a422b6f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(25,22))\n",
    "sns.heatmap(df.corr(),linewidths=.1,vmin=-1, vmax=1, fmt='.2g', annot = True, linecolor=\"black\",annot_kws={'size':15},cmap=\"YlGnBu\")\n",
    "plt.yticks(rotation=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22378097",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f02b65a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#SPLITTING THE DATA SET\n",
    "x=df.drop('Income',axis=1)\n",
    "y=df['Income']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bac2cb57",
   "metadata": {},
   "outputs": [],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d78b204",
   "metadata": {},
   "outputs": [],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11e9533e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def vif_calc():\n",
    "  vif=pd.DataFrame()\n",
    "  vif[\"VIF Factor\"]=[variance_inflation_factor(x.values,i) for i in range(x.shape[1])]\n",
    "  vif[\"features\"]=x.columns\n",
    "  print(vif)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1d68f24",
   "metadata": {},
   "outputs": [],
   "source": [
    "vif_calc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "886f2a9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Scaling the Data\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc=StandardScaler()\n",
    "x=pd.DataFrame(sc.fit_transform(x), columns=x.columns)\n",
    "x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "878c47bf",
   "metadata": {},
   "source": [
    "# MODELLING FOR INCOME\n",
    "Building CLASSIFICATION Model As Target Column's Has only Two Outputs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43c2e44f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "print(df['Income'].value_counts())  \n",
    "plt.figure(figsize=(5,5))\n",
    "sns.countplot(df['Income'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52919954",
   "metadata": {},
   "outputs": [],
   "source": [
    "#OverSampling\n",
    "from imblearn.over_sampling import SMOTE\n",
    "sm = SMOTE()\n",
    "x, y = sm.fit_resample(x,y)\n",
    "y.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73920b56",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Modelling to Get the best random state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f042a16",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier as KNN\n",
    "from sklearn.ensemble import GradientBoostingClassifier, BaggingClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_curve, accuracy_score\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "maxAccu=0\n",
    "maxRS=0\n",
    "\n",
    "for i in range(1,200):\n",
    "    x_train,x_test, y_train, y_test=train_test_split(x,y,test_size=.30, random_state=i)\n",
    "    rfc=RandomForestClassifier()\n",
    "    rfc.fit(x_train,y_train)\n",
    "    pred=rfc.predict(x_test)\n",
    "    acc=accuracy_score(y_test,pred)\n",
    "    if acc>maxAccu:\n",
    "        maxAccu=acc\n",
    "        maxRS=i\n",
    "print(\"Best accuracy is \",maxAccu*100,\" on Random_state \",maxRS)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f518d30f",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=.30,random_state=maxRS)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "576a8dd3",
   "metadata": {},
   "source": [
    "# Logistic Regression\n",
    "# Checking Accuracy for Logistic Regression\n",
    "log = LogisticRegression()\n",
    "log.fit(x_train,y_train)\n",
    "\n",
    "#Prediction\n",
    "predlog = log.predict(x_test)\n",
    "\n",
    "print(accuracy_score(y_test, predlog)*100)\n",
    "print(confusion_matrix(y_test, predlog))\n",
    "print(classification_report(y_test,predlog))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d50350b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting Confusion_Matrix\n",
    "cm = confusion_matrix(y_test,predlog)\n",
    "\n",
    "x_axis_labels = [\"0\",\"1\"]\n",
    "y_axis_labels = [\"0\",\"1\"]\n",
    "\n",
    "f , ax = plt.subplots(figsize=(5,5))\n",
    "sns.heatmap(cm, annot = True,linewidths=.2, linecolor=\"black\", fmt = \".0f\", ax=ax, cmap=\"BuGn\",xticklabels=x_axis_labels,yticklabels=y_axis_labels)\n",
    "plt.xlabel(\"PREDICTED LABEL\")\n",
    "plt.ylabel(\"TRUE LABEL\")\n",
    "plt.title('Confusion Matrix for LogisticRegression')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "087af10d",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Random Forest Classifier\n",
    "# Checking accuracy for Random Forest Classifier\n",
    "rf = RandomForestClassifier()\n",
    "rf.fit(x_train,y_train)\n",
    "\n",
    "# Prediction\n",
    "predrf = rf.predict(x_test)\n",
    "\n",
    "print(accuracy_score(y_test, predrf)*100)\n",
    "print(confusion_matrix(y_test, predrf))\n",
    "print(classification_report(y_test,predrf))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c30030ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets plot confusion matrix for RandomForestClassifier\n",
    "cm = confusion_matrix(y_test,predrf)\n",
    "\n",
    "x_axis_labels = [\"0\",\"1\"]\n",
    "y_axis_labels = [\"0\",\"1\"]\n",
    "\n",
    "f , ax = plt.subplots(figsize=(5,5))\n",
    "sns.heatmap(cm, annot = True,linewidths=0.2, linecolor=\"black\", fmt = \".0f\", ax=ax, cmap=\"BuGn\",xticklabels=x_axis_labels,yticklabels=y_axis_labels)\n",
    "plt.xlabel(\"PREDICTED LABEL\")\n",
    "plt.ylabel(\"TRUE LABEL\")\n",
    "plt.title('Confusion Matrix for RandomForestClassifier')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2efb1595",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Decission Tree Classifier\n",
    "# Checking Accuracy for Decision Tree Classifier\n",
    "dtc = DecisionTreeClassifier()\n",
    "dtc.fit(x_train,y_train)\n",
    "\n",
    "#Prediction\n",
    "preddtc = dtc.predict(x_test)\n",
    "\n",
    "print(accuracy_score(y_test, preddtc)*100)\n",
    "print(confusion_matrix(y_test, preddtc))\n",
    "print(classification_report(y_test,preddtc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66a75901",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets plot confusion matrix for Decission Tree Classifier\n",
    "cm = confusion_matrix(y_test,preddtc)\n",
    "\n",
    "x_axis_labels = [\"0\",\"1\"]\n",
    "y_axis_labels = [\"0\",\"1\"]\n",
    "\n",
    "f , ax = plt.subplots(figsize=(5,5))\n",
    "sns.heatmap(cm, annot = True,linewidths=.2, linecolor=\"black\", fmt = \".0f\", ax=ax, cmap=\"BuGn\",xticklabels=x_axis_labels,yticklabels=y_axis_labels)\n",
    "plt.xlabel(\"PREDICTED LABEL\")\n",
    "plt.ylabel(\"TRUE LABEL\")\n",
    "plt.title('Confusion Matrix for Decision Tree Classifier')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a66cd5bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Support Vector Machine Classifier\n",
    "# Checking accuracy for Support Vector Machine Classifier\n",
    "svc = SVC()\n",
    "svc.fit(x_train,y_train)\n",
    "\n",
    "# Prediction\n",
    "predsvc = svc.predict(x_test)\n",
    "\n",
    "print(accuracy_score(y_test, predsvc)*100)\n",
    "print(confusion_matrix(y_test, predsvc))\n",
    "print(classification_report(y_test,predsvc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed2af041",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets plot confusion matrix for Support Vector Machine Classifier\n",
    "cm = confusion_matrix(y_test,predsvc)\n",
    "\n",
    "x_axis_labels = [\"0\",\"1\"]\n",
    "y_axis_labels = [\"0\",\"1\"]\n",
    "\n",
    "f , ax = plt.subplots(figsize=(5,5))\n",
    "sns.heatmap(cm, annot = True,linewidths=.2, linecolor=\"black\", fmt = \".0f\", ax=ax, cmap=\"BuGn\",xticklabels=x_axis_labels,yticklabels=y_axis_labels)\n",
    "\n",
    "plt.xlabel(\"PREDICTED LABEL\")\n",
    "plt.ylabel(\"TRUE LABEL\")\n",
    "plt.title('Confusion Matrix for Support Vector Machine Classifier')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1af4de9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Gradient Boosting Classifier\n",
    "# Checking accuracy for Gradient Boosting Classifier\n",
    "GB = GradientBoostingClassifier()\n",
    "GB.fit(x_train,y_train)\n",
    "\n",
    "# Prediction\n",
    "predGB = GB.predict(x_test)\n",
    "\n",
    "print(accuracy_score(y_test, predGB)*100)\n",
    "print(confusion_matrix(y_test, predGB))\n",
    "print(classification_report(y_test,predGB))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2a5aab1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets plot confusion matrix for Gradient Boosting Classifier\n",
    "cm = confusion_matrix(y_test,predGB)\n",
    "\n",
    "x_axis_labels = [\"0\",\"1\"]\n",
    "y_axis_labels = [\"0\",\"1\"]\n",
    "\n",
    "f , ax = plt.subplots(figsize=(5,5))\n",
    "sns.heatmap(cm, annot = True,linewidths=.2, linecolor=\"black\", fmt = \".0f\", ax=ax, cmap=\"BuGn\",xticklabels=x_axis_labels,yticklabels=y_axis_labels)\n",
    "\n",
    "plt.xlabel(\"PREDICTED LABEL\")\n",
    "plt.ylabel(\"TRUE LABEL\")\n",
    "plt.title('Confusion Matrix for Gradient Boosting Classifier')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ee36df3",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Cross Validation Score\n",
    "#cv score for Logistic Regression\n",
    "print(cross_val_score(log,x,y,cv=5).mean()*100)\n",
    "\n",
    "# cv score for Decision Tree Classifier\n",
    "print(cross_val_score(dtc,x,y,cv=5).mean()*100)\n",
    "\n",
    "# cv score for Random Forest Classifier\n",
    "print(cross_val_score(rf,x,y,cv=5).mean()*100)\n",
    "\n",
    "# cv score for Support Vector  Classifier\n",
    "print(cross_val_score(svc,x,y,cv=5).mean()*100)\n",
    "\n",
    "# cv score for Gradient Boosting Classifier\n",
    "print(cross_val_score(GB,x,y,cv=5).mean()*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a84526db",
   "metadata": {},
   "source": [
    "# it is clear from the above that Random Forest Classifier is working the best with respect to Cross validation score as well which is minimum in the case..\n",
    "\n",
    "So we move forward with Random Forest Classifier Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e120b2b",
   "metadata": {},
   "source": [
    "##HyperParameter Tuning for the model with best score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d801543",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Random Forest Classifier\n",
    "\n",
    "parameters = {'criterion':['gini'],\n",
    "             'max_features':['auto'],\n",
    "             'n_estimators':[0,200],\n",
    "             'max_depth':[2,3,4,5,6,8]}\n",
    "GCV=GridSearchCV(RandomForestClassifier(),parameters,cv=5)\n",
    "GCV.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e64c7d19",
   "metadata": {},
   "outputs": [],
   "source": [
    "GCV.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bbd3634",
   "metadata": {},
   "outputs": [],
   "source": [
    "Incomee =RandomForestClassifier (criterion='gini', max_depth=8, max_features='auto', n_estimators=200)\n",
    "Incomee.fit(x_train, y_train)\n",
    "pred = Incomee.predict(x_test)\n",
    "acc=accuracy_score(y_test,pred)\n",
    "print(acc*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e357bea",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Plotting ROC and compare AUC for the final model\n",
    "from sklearn.metrics import plot_roc_curve\n",
    "plot_roc_curve(rf,x_test,y_test)\n",
    "plt.title(\"ROC AUC Plot\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc4bd238",
   "metadata": {},
   "source": [
    "Conclusion:\n",
    "The accuracy score for Income is 84 %"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33dd5679",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Saving the model\n",
    "import joblib\n",
    "joblib.dump(Incomee,\"Census_Income.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70da91d0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d2761a9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
